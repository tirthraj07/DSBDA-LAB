# Data Science and Big Data Analytics Lab

<table border="1">
<thead>
  <tr>
    <th>Sr.</th>
    <th>Name</th>
    <th colspan=2>Description</th>
  </tr>
</thead>
<tbody>
    <tr>
      <td>1</td>
      <td>Data Wrangling I</td>
      <td colspan="2">
      Perform the following operations using Python on any open-source dataset (e.g., data.csv)
        1. Import all the required Python Libraries.
        2. Locate an open-source data from the web (e.g.
        https://www.kaggle.com). Provide a clear description of the data and its source (i.e., URL of the web site).
        3. Load the Dataset into pandas’ data frame.
        4. Data Preprocessing: check for missing values in the data using pandas isnull (), describe() function to get some initial
        statistics. Provide variable descriptions. Types of variables
        etc. Check the dimensions of the data frame.
        5. Data Formatting and Data Normalization: Summarize the
        types of variables by checking the data types (i.e., character,
        numeric, integer, factor, and logical) of the variables in the
        data set. If variables are not in the correct data type, apply
        proper type conversions.
        6. Turn categorical variables into quantitative variables in Python.
        In addition to the codes and outputs, explain every operation that you do in the above steps and explain everything that you do to import/read/scrape the data set.
      </td>
    </tr>

    <tr>
      <td>2</td>
      <td>Data Wrangling II</td>
      <td colspan="2">
        Create an “Academic performance” dataset of students and perform the following operations using Python.
        1. Scan all variables for missing values and inconsistencies. If there are missing values and/or inconsistencies, use any of the suitable techniques to deal with them.
        2. Scan all numeric variables for outliers. If there are outliers, use any of the suitable techniques to deal with them.
        3. Apply data transformations on at least one of the variables. The purpose of this transformation should be one of the following reasons: to change the scale for better understanding of the variable, to convert a non-linear relation into a linear one, or to decrease the skewness and convert the distribution into a normal distribution.
        Reason and document your approach properly.
      </td>
    </tr>

    <tr>
      <td>3</td>
      <td>Descriptive Statistics : Measures of Central Tendency and Variability</td>
      <td colspan="2">
        Perform the following operations on any open-source dataset
        1.	`[nba.csv]` Provide summary statistics (mean, median, minimum, maximum, standard deviation) for a dataset (age, income etc.) with numeric variables grouped by one of the qualitative (categorical) variable. For example, if your categorical variable is age groups and quantitative variable is income, then provide summary statistics of income grouped by the age groups. Create a list that contains a numeric value for each response to the categorical variable.
        2.	`[iris.csv]` Write a Python program to display some basic statistical details like percentile, mean, standard deviation etc. of the species of ‘Iris-setosa’, ‘Iris-versicolor’ and ‘Iris- verginica’ of iris.csv dataset.
        Provide the codes with outputs and explain everything that you do in this step.
      </td>
    </tr>


    <tr>
      <td>4</td>
      <td>Data Visualization I</td>
      <td colspan="2">
        1. Use the inbuilt dataset 'titanic'. The dataset contains 891 rows and contains information about the passengers who boarded the unfortunate Titanic ship. Use the Seaborn library to see if we can find any patterns in the data.
        2. Write a code to check how the price of the ticket (column
        name: 'fare') for each passenger is distributed by plotting a histogram.
      </td>
    </tr>

    <tr>
      <td>5</td>
      <td>Data Visualization II</td>
      <td colspan="2">
        1.	Use the inbuilt dataset 'titanic' as used in the assignment #4. Plot a box plot for distribution of age with respect to each gender along with the information about whether they survived or not. (Column names: 'sex' and 'age')
        2.	Write observations on the inference from the above statistics.
      </td>
    </tr>

    <tr>
      <td>6</td>
      <td>Data Visualization III</td>
      <td colspan="2">
        Download the Iris flower dataset (`iris.csv`) or any other dataset into a DataFrame. (e.g., https://archive.ics.uci.edu/ml/datasets/Iris). 
        Scan the dataset and give the inference as:
        1.	 List down the features and their types (e.g., numeric, nominal) available in the dataset.
        2.	 Create a histogram for each feature in the dataset to illustrate the feature distributions.
        3.	 Create a box plot for each feature in the dataset.
        4.	 Compare distributions and identify outliers.
      </td>
    </tr>

    <tr>
      <td>7</td>
      <td>Data Analytics I</td>
      <td colspan="2">
        Create a Linear Regression Model using Python/R to predict home prices using Boston Housing Dataset (https://www.kaggle.com/c/boston-housing). The Boston Housing dataset contains information about various houses in Boston through different parameters. There are 506 samples and 14 feature variables in this dataset.
        The objective is to predict the value of prices of the house using the given features.
      </td>
    </tr>

    <tr>
      <td>8</td>
      <td>Data Analytics - II</td>
      <td colspan="2">
        Problem Statement
        1.	Implement	logistic	regression	using	Python /R to perform classification on Social_Network_Ads.csv dataset.
        2.	ComputeConfusionmatrixtofindTP,FP,TN,FN,Accuracy, Errorrate, Precision,Recall on the given dataset.
      </td>
    </tr>

    <tr>
      <td>9</td>
      <td>Data Analytics III</td>
      <td colspan="2">
        Implement Simple Naïve Bayes classification algorithm using Python/R on iris.csv dataset.   
        Compute Confusion matrix to find TP, FP, TN, FN, Accuracy, Error rate, Precision, Recall on the given dataset.
      </td>
    </tr>

    <tr>
      <td>10</td>
      <td>Text Analytics</td>
      <td colspan="2">
        1. Extract Sample document and apply following document preprocessing methods: Tokenization, POS Tagging, stop words removal, Stemming and Lemmatization.
        2. Create representation of document by calculating Term Frequency and Inverse Document Frequency
      </td>
    </tr>

    <tr>
      <td>11</td>
      <td>Hadoop Word Count</td>
      <td colspan="2">
      Write a code in JAVA for a simple Word Count application that counts the number of occurrences of each word in a given input set using the Hadoop Map-Reduce framework on local-standalone set-up.
      </td>
    </tr>

    <tr>
      <td>13</td>
      <td>Apache Spark Word Count</td>
      <td colspan="2">Write a simple program in SCALA using the Apache Spark Framework</td>
    </tr>
</tbody>
</table>